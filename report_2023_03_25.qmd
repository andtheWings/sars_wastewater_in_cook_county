---
title: "Status Update for March 25th, 2023"
date: 2023-03-25
author: Daniel P. Hall Riggins
format: 
    html:
        embed-resources: true
---

## Prep

```{r}
#| output: false
library(targets)
library(tidyverse)
library(lubridate)
library(timetk)
library(plotly)
sapply(
    paste0("R/", list.files("R/")),
    source
)
```

Here I load my data. I have created a series of upstream data wrangling steps that culminate in a list containing separate dataframes for each WWTP and one for the aggregation of all plants.

```{r}
load("data/2023-01-27_hosp-metrics.Rdata")
tar_make()
tar_load(nwss)
```

Dataframes can be queried with the following names:

```{r}
names(nwss)
```

Here is the dataframe for the aggregation of all WWTP's:

```{r}
glimpse(nwss$cook_aggregate)
```
And here is the dataframe for ED admissions:

```{r}
glimpse(cli)
```

I have created a function (discussed previously) that fits a spline to a numerical variable along with corresponding z-score for the spline, slope of the spline, and percent daily change of the slope:

```{r}
add_spline_and_slope
```

The purpose of the standardized .z_spline and the .percent_daily_change variables is to enable comparison between time-series with different unit scales.

In practice, you just tack the function onto the dataframe for which you want a spline fitted.

```{r}
cli |> 
    filter(date >= ymd("2022-02-15") & date < ymd("2023-01-01")) |> 
    add_spline_and_slope("cli") |> 
    glimpse()
```

## Comparing Emergency Department and Wastewater Trends

Here are ED visit dynamics fitted with a spline across 2022:

```{r}
cli_2022_and_spline <-
    cli |> 
    filter(date >= ymd("2022-02-15") & date < ymd("2023-01-01")) |> 
    add_spline_and_slope("cli")

ggplotly(
    cli_2022_and_spline |>  
    ggplot(aes(x = date)) +
    geom_point(aes(y = cli), alpha = 0.25, color = "blue") +
    geom_line(aes(y = .spline), color = "blue") +
    labs(
        title = "Percent ED visits due to COVID-like Illness",
        x = NULL,
        y = NULL
    ) +
    theme_bw()
)
```


Which follows a vaguely similar shape to aggregate wastewater trends across the same time period:

```{r}
cook_aggregate_and_spline <- 
    nwss$cook_aggregate |> 
    filter(date >= ymd("2022-02-15") & date < ymd("2023-01-01")) |> 
    add_spline_and_slope("conc_flowrt_sum")

ggplotly(
    cook_aggregate_and_spline |>  
    ggplot(aes(x = date)) +
    geom_point(aes(y = conc_flowrt_sum), alpha = 0.25, color = "black") +
    geom_line(aes(y = .spline), color = "black") +
    labs(
        title = "Total SARS-CoV-2 Viral Copies per Day",
        x = NULL,
        y = NULL
    ) +
    theme_bw()
)
```

Let's compare the standardized splines across time to see if one tends to precede the other:

```{r}
ggplotly( 
    ggplot() +
    geom_line(aes(x = date, y = .z_spline), color = "blue", data = cli_2022_and_spline) +    
    geom_line(aes(x = date, y = .z_spline), color = "red", data = cook_aggregate_and_spline) +
    labs(
        title = "Standardized %ED visits for COVID-like Illness (blue) <br> and SARS-CoV-2 Viral Copies in WWTP's per Day (red)",
        x = NULL,
        y = NULL
    ) +
    theme_bw()
)
```

One trend does not consistently precede the other. As such, when using an early warning system, I expect both trends to be more useful that either one alone.

## Simulating Real-Time Information

In the context of an early warning system, we will be running up against the forward edge of the time series. This decreases spline fit accuracy. To illustrate, I have made a function for visualizing a series of splines as time moves forward:

```{r}
plot_spline_snapshots
```

Watch how the spline estimate for March 10th changes over time. In the first plot, March 10th is at the leading edge of the time series with a value of 2.79. As time moves forward, the estimate for March 10th "bends" upward. In the last plot, the leading edge is now at March 14th and the value for March 10th has increased to 3.31.

```{r}
spline_snapshot_plots <-
    nwss$cook_aggregate |> 
    filter(date >= ymd("2022-02-15") & date < ymd("2023-01-01")) |> 
    plot_spline_snapshots(
        date_vct_slice = 50:60, 
        y_var = "conc_flowrt_sum", 
        title_char = "Total SARS-CoV-2 Viral Copies per Day"
    )    
spline_snapshot_plots[[3]]
```
```{r}
spline_snapshot_plots[[3]]
```

```{r}
spline_snapshot_plots[[5]]
```

The last fit for March 10th is probably more accurate, but in the context of early warning systems, we will not have the benefit of hindsight. 

To add data about what the spline fit would have looked like at the leading edge for each time point, I have created the following function:

```{r}
add_spline_snapshots
```

We see that using these snapshots, the signal gets substantially noisier, but more truthfully describes what the state of our knowledge would have been at each time point:

```{r}
cook_aggregate_spline_snapshots <- add_spline_snapshots(cook_aggregate_and_spline, "conc_flowrt_sum")
cli_2022_spline_snapshots <- add_spline_snapshots(cli_2022_and_spline, "cli")

ggplotly(
    cook_aggregate_spline_snapshots |> 
        ggplot(aes(x = date)) +
        geom_point(aes(y = conc_flowrt_sum), alpha = 0.25) +
        geom_line(aes(y = .spline), color = "red") +
        geom_line(aes(y = .spline_snapshot), color = "maroon") + 
        theme_bw() +
        labs(
            title = "SARS-CoV-2 Viral Copies per Day <br> Full Spline (red), Spline Snapshots (Maroon)",
            x = NULL,
            y = NULL
        )
)
```


When assessing our Early Warning System, I will use snapshots based on leading edges rather than a spline fit on the whole range of data.

## Choosing a Trigger Threshold for Early Warning

Following the trends for both ED visits and Wastewater viral copies, we see that there is no consistent baseline to which a trend returns after a surge. This makes it difficult to set a threshold for triggering early warning. Fortunately, the .spline_slope and .percent_daily_change trends do have a consistent baseline of zero, making them more suitable for setting a consistent threshold. Here are the trends using all available data:

```{r}
ggplotly(
    ggplot() +
    geom_line(aes(x = date, y = .percent_daily_change), color = "blue", data = cli_2022_spline_snapshots) +    
    geom_line(aes(x = date, y = .percent_daily_change), color = "red", data = cook_aggregate_spline_snapshots) +
    labs(
        title = "Percent Daily Change for <br> ED visits due to COVID-like Illness (blue) <br> and SARS-CoV-2 Viral Copies per Day (red)",
        x = NULL,
        y = NULL
    ) +
    #coord_cartesian(ylim = c(-8, 8)) +
    theme_bw()
)
```

And here are the same trends using snapshots of the information we would have had at the leading edge of each date:

```{r}
ggplotly(
    ggplot() +
    geom_line(aes(x = date, y = .pdc_snapshot), color = "blue", data = cli_2022_spline_snapshots) +    
    geom_line(aes(x = date, y = .pdc_snapshot), color = "red", data = cook_aggregate_spline_snapshots) +
    labs(
        title = "Snapshots of Percent Daily Change for <br> ED visits due to COVID-like Illness (blue) <br> and SARS-CoV-2 Viral Copies per Day (red)",
        x = NULL,
        y = NULL
    ) +
    coord_cartesian(ylim = c(-8, 8)) +
    theme_bw()
)
```

Again, the signal is much noisier, but more truthful. We see that when one or both trends have a percent daily change of one or greater, this roughly corresponds to the surges. 

Below, I combine data on trends for both ED visits and Wastewater into one dataframe and export.

I have annotated that data in Excel, marking when an Alarm would be triggered on. 

```{r}
#| output: false
cook_aggregate_pdc_snapshots <-
    cook_aggregate_spline_snapshots |> 
    select(
        date,
        .nwss_pdc_snapshot = .pdc_snapshot
    ) 

cli_2022_pdc_snapshots <- 
    cli_2022_spline_snapshots |> 
    select(
        date,
        .cli_pdc_snapshot = .pdc_snapshot 
    )
    
combined_pdc_snapshots <- 
    full_join(cook_aggregate_pdc_snapshots, cli_2022_pdc_snapshots, by = "date") |> 
    arrange(date)


write_csv(combined_pdc_snapshots, "combined_pdc_snapshots.csv")

test_thresholds <- read_csv("data/test_thresholds.csv")
test_inputs <- read_csv("data/test_inputs.csv")
```

I started by marking the warning alarm as on if either ED or Wastewater Percent Daily Change was above a certain threshold. Below, I have visualized the Warning periods based on thresholds of 1, 1.5, or 2 percent daily change. These periods are superimposed on the overall trend of ED visits for reference.

```{r}
ggplotly(
    ggplot() +
    geom_point(aes(x = date, y = cli), alpha = 0.25, color = "blue", data = cli_2022_and_spline) +
    geom_line(aes(x = date, y = .spline), color = "blue", data = cli_2022_and_spline) +
    geom_rect(aes(xmin = date_min, xmax = date_max, ymin = y_min, ymax = y_max, fill = threshold), data = test_thresholds) +
    labs(
        title = "%ED visits for COVID-like Illness with Alarm Periods",
        x = NULL,
        y = NULL,
        fill = "PDC Warning Trigger"
    ) +
    theme_bw()
) |> 
layout(hovermode = "x unified")
```

Among the three three options, it seems like a threshold of 1.5 percent daily change strikes roughly the right balance between sensitivity and specificity to surge periods.

For the surge around April 10th, it would have triggered a warnings on March 20th (21 days early) and April 3rd (7 days early).

For the surge around July 5th, it would have triggered a warning on June 17th (18 days early) and July 2nd (3 days early).

For the surge around October 25th, it would have triggered a warning on October 20th (5 days early).

## Does Wastewater Add Value?

These trigger dates don't seem any better than those you shared based on your ED Early Warning Indicator alone. Let's test under my system if including the wastewater trend makes much of a difference:


```{r}
ggplotly(
    ggplot() +
    geom_point(aes(x = date, y = cli), alpha = 0.25, color = "blue", data = cli_2022_and_spline) +
    geom_line(aes(x = date, y = .spline), color = "blue", data = cli_2022_and_spline) +
    geom_rect(aes(xmin = date_min, xmax = date_max, ymin = y_min, ymax = y_max, fill = input), data = test_inputs) +
    labs(
        title = "%ED visits for COVID-like Illness with Alarm Periods",
        x = NULL,
        y = NULL,
        fill = "PDC Warning Input(s)"
    ) +
    theme_bw()
) |> 
    layout(hovermode = "x unified")
```

For the most part, including wastewater trends in the early warning system does not seem to have made a huge difference. The exceptions are an alarm on August 4th for a mini-surge not picked up using the ED alone and an alarm in November starting slightly early (Nov 20th vs Nov 24th).

## Conclusion

Overall, it seems like the computational cost of including wastewater trends in the warning system would be low once the system is set up, but the marginal benefit of earlier warnings also seems low.